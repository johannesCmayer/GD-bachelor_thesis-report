% !TEX root = BachelorBookletMain.tex

\newcommand{\neuronSum}[1][n]{
	\sigma\Bigg(\sum_{i=1}^{#1}{\Big(w_i x_i\Big)} + b\Bigg)
}

\chapter{Background}
\section{Neural networks}
To give a better intuition for how neural networks work and how they are used in this project, a brief overview follows describing the components necessary to build a simple neural network.

In brief a neural network is computational structure made up of multiple units called neurons that can adapt their output based on data.


\subsection{Neuron}
A simple neuron can be defined as:

\begin{equation}
\begin{split}
	N_{\bm w, b}(\bm{x}) & = \neuronSum[n] \\
 	& = \sigma (\bm{w} \cdot \bm{x} + b)
\end{split}
\end{equation}

Where $\bm{x} \in \mathbb{R}^n$ is a vector containing all inputs, $ \bm{w} \in \mathbb{R}^n$ a vector containing the neurons weights, $b \in \mathbb{R}$ is the bias, $n \in \mathbb{Z}$ is the number of inputs and $\sigma$ is a nonlinear function refereed to as the activation function of the neuron. $\sigma$ is often set to be the rectified linear unit $ReLU(x) = \max(0, x)$.

Intuitively a neuron performs a weighted sum over its inputs adds a bias and applies an activation function to the result to calculate the final output. The bias can be thought of as a threshold, determining---if $\sigma = ReLU$---how high the sum of inputs has to be, before the output becomes non 0. \Cref{neuronGraph} shows, how we can think of a neuron as having connections, where the entirety of the connections form the input vector.

\neuronGraph{p}{$\displaystyle{\neuronSum[3]}$}


\subsection{Multilayer network}
As seen in \cref{multilayerNetworkGraph} a neural network work can be formed out of neurons by first organizing multiple neurons into a layers\footnote{In \cref{multilayerNetworkGraph} a layer is a collection of neurons that line up vertically.} and then connecting multiple layers together. To get a dense network each neuron in a layer gets as inputs the outputs of all the neurons in the previous\footnote{The layer to the left} layer. The first layer is used to provide the input to the network. We can simply set the output values of the neurons to what we like to have as inputs to the network. To get the output of the network we read of what values the neurons in the final layer have after the network has been evaluated. The layers between the first and last layer are called hidden layers. This is because it is normally not necessary to inspect directly what values or parameters these neurons have.

\multilayerNetworkGraph[p]

Normally in an implementations of a densely connected neural network the computer performs multiple matrix operations to compute the output. This is usually more efficient because many matrix operations, in implementations we would use, are heavily optimized. \Cref{networkMatrixMul} shows how to compute the values for the first hidden layer of the network in \cref{multilayerNetworkGraph} this way. The $\sigma$ is applied to each element of the vector.

\begin{equation}
	Hidden_1(\bm{x}) = \sigma\Bigg{(}
	\directlua{
		print_matrix('w', 4, 3)
		print_matrix('x', 3)
		tex.print('+')
		print_matrix('b', 4)
	}
	\Bigg{)}
	\label{networkMatrixMul}
\end{equation}


\subsection{Training}
Before we start training we need to set our weights and biases to some start values.
The bias is usually initialized to 0 and the weights can be initialized to small random values if the network is small enough. More complicated initialization strategies are needed for the weights if we are dealing with a big network (\cite{Glorot2010-kn, Ioffe2015-eh}).

Normally we are interested in finding specific weight vectors and biases for neurons that make the network perform some specific task like image classification.

We might want to know if an image pictures an orange or an apple. For this task we can use a network with one output neuron, where that neurons value should be one if we feed in a picture of an orange and zero if we feed in a picture of an apple. If we now feed in a picture, the network gives back some arbitrary numerical value that will only by chance predict the correct fruit. This is because the network is not trained yet.

To train the network we first need to define a loss function. This function returns a numerical value that represents how bad the network is. For images we may use the means square error function as shown in \cref{MSE}. There $\bm{x}$ is the output of the network and $\bm{y}$ is our desired output.

\begin{equation}
	MSE(\bm{x}, \bm{y}) = \frac{1}{n}\sum_{i=1}^{n}{(\bm{x}_i - \bm{y}_i)^2}
	\label{MSE}
\end{equation}

To train the network we need a dataset of input and desired output pairs. To create a dataset we first need a bunch of images of apples and oranges. Then we pair each image with the number one if the image depicts an orange and the number zero if the image depicts an apple.

Now if we feed in an image into the network we can measure how bad the network is using the loss function. To improve the output of the network, we train it by adjusting our weights and biases proportionally to the negative gradient of the loss function with respect to the weights and biases using calculus.


\section{Differential calculus}
Differential Calculus is an area of mathematics that studies how a functions output changes with regard to tiny nudges to its inputs.


\subsection{Univariate}
The derivative can intuitively be interpreted as giving the value of how fast the output of a function changes as well as the direction of change\footnote{The output either increases or decreases if we increase $x$.} at a specific point if we start to increase $x$. It is defined as:

\begin{equation}
	\frac{df(x)}{dx} = \lim_{dx \to 0}\frac{f(x + dx) - f(x)}{dx}
\end{equation}

The $\lim_{dx \to 0}$ means, that we don't use a specific value for $dx$ but take the value the equation approaches when $dx$ approaches $0$ without $dx$ ever becoming $0$.

This means that the derivative can be used to find out how a function changes locally. If the derivative is positive and we increase the input to the function, at the point the derivative was evaluated, the output increases in size. This increase is proportional to the magnitude of the derivative. The same logic applies when the derivative is negative.


\subsection{Multivariate}
The same can be applied to functions with multiple parameters:

\begin{equation}
\begin{split}
	\frac{\partial f(x_1, x_2)}{\partial x_1} = \lim_{\partial x_1 \to 0}\frac{f(x_1 + \partial x_1, x_2) - f(x_1, x_2)}{\partial x_1} \\
	\frac{\partial f(x_1, x_2)}{\partial x_2} = \lim_{\partial x_2 \to 0}\frac{f(x_1, x_2 + \partial x_2) - f(x_1, x_2)}{\partial x_2}
\end{split}
\end{equation}

Here each equation defines as how much the output of the function changes locally when the corresponding input parameter to the function increases.
The gradient of a function is a vector containing the derivative information with respect to each parameter. The gradient of $f(x_1, x_2)$ is defined as:

\begin{equation}
\nabla f(x_1, x_2) =
	\begin{bmatrix}
	\frac{\partial f(x_1, x_2)}{\partial x_1} \\[2mm]
	\frac{\partial f(x_1, x_2)}{\partial x_2}
	\end{bmatrix}
\end{equation}

Calculating the gradient of the loss gives us the information of how we should adjust our weights and biases to improve the loss i.e. improve the output of the network. Normally we scale the gradient by some learning rate $\eta \in \mathbb{R}$.


\section{GQN Network}\label{BackgroundGQN}
\subsection{Definition}
A Generative Query Network (\cite{gqn}) is a type of neural network architecture that can learn to render an image from a queried viewpoint in an environment. The output of the network is then, in the ideal case, identical to an image a camera would produce when placed at the same queried viewpoint in the same environment.

The network can perform this rendering even for environments that where not seen during training. This works because the network constructs a representation of the current environment for each render (\cref{GQNArchitectureGraph}). To generate this representation we need to input a few\footnote{How many images we use is a hyperparameter.} image-coordinate pairs into the network. These image-coordinate pairs need to be of the environment that we want the network to render. The coordinate that is paired with an image denotes where\footnote{The coordinate includes the position and rotation.} that image was taken.

During training the network has learned how to encode these image-coordinate pairs into an abstract representation of the environment. Also, the network learned how to use this representation to render an image from a queried viewpoint. The closer the unseen environment is to environments seen during training, in terms of objects in the environment and their properties, the better the network is expected to perform. One thing the network is very good at is to learn where objects, that appeared in the training set, are placed in an environment, even if an object was never observed to be positioned in this particular way in any environment. To some extend the network is able to correctly render objects not present in any training environment (\cite{gqn}).

The network architecture is shown in \cref{GQNArchitectureGraph}, where $I_1$ denotes an image of an environment and $C_1$ the position and rotation where the image was taken. The $\bigcup$ here means concatenation. All $R_i$ are, as tensors encoded, representations of the environment. These tensors are summed up element wise over all tensors so that $R$ has the same dimensionality as $R_i$. $C_q$ is the coordinate from which the network should render an Image, $z$ is a vector of latent variables and $I_y$ is the ground truth image of what a render form $C_q$ looks like. The encoder and decoder are both neural networks.

To train the network we feed image-coordinate pairs and compute the gradient of the loss. For the target output and the query position we use an image-coordinate pair from the same environment. With the gradient of the loss we can then update the network parameters. All $(I_i, C_i)$ and $(I_y, C_q)$ have to be drawn from the same environment in one evaluation of the network. If there are multiple $(I_i, C_i)$ input pairs, the same encoder network is used to encode each of them. The update procedure has to be repeated many times until the network output reaches the desired quality.

\GQNArchitectureGraph


\subsection{Usage}
This work uses a simplified implementation of the Generative Query Network.

In this work the architecture of the used neural network differs from the implementation of the GQN used in the original paper. Here I use simple dense models for the encoder and decoder that don't use random latent variables. This circumvents the necessity of having to use the evidence lower bound as an optimization target.

This however limits the networks abilities. It does not take into account the inputs, given during inference\footnote{Producing output without training a network.}, to the same extent as in the original experiments described in \cite{gqn}. The only meaningful considerations of the inputs of the network, that where given during inference, were found to be the coloring of the sky, floor and walls (\cref{FunctionalFirstPerson}). These only worked on static objects. In the original implementation the network can correctly infer more properties like object position, rotation, color and texture on nonstatic\footnote{Nonstatic referees to objects that change their position between environments. An any given environment objects are still static.} objects.

Because interesting use cases where found that do not depend on these properties of a GQN network, no more effort was put into recreating the abilities of the original implementation.
