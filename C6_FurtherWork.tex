% !TEX root = BachelorBookletMain.tex

\chapter{Further work}\label{FurtherWork}
This chapter presents possible future directions of how the project can be expanded upon.


\section{Interactive data generation}
One additional layer of interactivity could be created by giving the player control over how the network trains. Specifically the player could control the generation of the training data. One way to achieve this is by allowing the player to traverse the unity environment and take screenshots of it via a keypress \footnote{or alternatively we could record what the player sees each moment as a series of images}. The captured images would then be used to train a neural network. After training the player would have to fulfill some task in the environment, but now he has to use the output of the network he trained to navigate the environment.

This could be used to create a competitive multiplayer game where both players first have to train a network and then use the output of their trained network to beat the other player at some task that has to be performed in the environment such as collecting objects, catching the other player or shooting the other player.


\section{Blending of internal network state}
One way to make the output of the neural network more interesting is by parameterizing the internal learned parameters. During training they would not have be variable, but after training the parameters can be manipulated to morph the output of the neural network. This morphing might be dependent on some dynamic gameplay values i.e. if the player shoots the laser the morphing could be set to height value and then gradually lerp back.


\section{Model improvements}
To enable more prototypes, the capability of the GQN network should be expanded so that it is as capable as the original implementation. The data generation process and preprocessing are capable of supplying such an implementation with the required data. This means that only the architecture of the model needs to be updated. Updating the network in this would would enable the development of the prototypes in the following subsections.


\subparagraph{Rendering nonstatic objects}
After the update the network would be able to directly render nonstatic objects. To capture the movement of objects, each frame a new observation from all observation points needs to be send to the encoder to update the environment representation, that is then used to render the output. Updating the representation each frame means that the output of the network would always represent where objects are in the environment at the present time.


\subsection{Interactive environment modeling}\label{PlayerEnvironmentModeling}
In this prototype the player manually updates the inputs to the GQN. For this he places some object in the environment, where the observations should be taken. To create more gameplay depth, the number of possible observations that can be taken per level and the total number of active observations should be limited in some way. This forces the player to strategize about when and where to take observations. Placing observations at a position would make the output of the network more accurate in the region the capturing object points in.
